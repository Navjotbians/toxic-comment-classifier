{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dir_path = os.path.dirname(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import sys  \n",
    "sys.path.append(os.path.join(dir_path, \"src\"))\n",
    "from word_embeddings import get_embeddings\n",
    "from clean_comments import clean\n",
    "from processing import process_txt\n",
    "from train import train_model\n",
    "from sklearn import feature_extraction, preprocessing, naive_bayes\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = os.path.join(dir_path, 'data', 'processed', 'processed_stem_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explan edit made usernam hardcor metallica fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>aww match background colour seemingli stuck th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man realli tri edit war guy constantli rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ca make real suggest improv wonder section sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chanc rememb page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0           0  0000997932d777bf      0             0        0       0       0   \n",
       "1           1  000103f0d9cfb60f      0             0        0       0       0   \n",
       "2           2  000113f07ec002fd      0             0        0       0       0   \n",
       "3           3  0001b41b1c6bb37e      0             0        0       0       0   \n",
       "4           4  0001d958c54c6e35      0             0        0       0       0   \n",
       "\n",
       "   identity_hate                                       comment_text  \n",
       "0              0  explan edit made usernam hardcor metallica fan...  \n",
       "1              0  aww match background colour seemingli stuck th...  \n",
       "2              0  hey man realli tri edit war guy constantli rem...  \n",
       "3              0  ca make real suggest improv wonder section sta...  \n",
       "4              0                         sir hero chanc rememb page  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill NA for any missing data \n",
    "df['comment_text'].fillna(\"missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "corpus = df['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Text Comments into Vectors using Bag-of-Words or TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that machine learning models doesn't accept input in the text format. So we need to convert the text data into vector form, it is also called **Word Embeddings**. Word Embeddings can be broadly classified as:\n",
    "1. Frequency based - Most popular techniques are **Bag-of-Words**, **TF-IDF**\n",
    "2. Prediction based - Most popular techniques are **Word2vec** and **Glove**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will be using **Bag-of-Words** and **TF-IDF**<br>\n",
    "<br>**Bag-of-Words(BOW)** - To get the embeddings with BOW technique, firstly we will have to make a dictionary with keys as a words from the test data and count of each word occurance as a value, then sort the dictionary in descending order of its values.Then these words from the dictionary are the names of our independed features and we can also choose how many features we want to use by selecting the top n words from the dictionary. Now these features will have values 0 or 1 based on if the word exists in the sentence.\n",
    "<br>\n",
    "**Disadvantage** of BOW - Word Embeddings have either 0's and 1's as a values, no weights are given to the words according to their importance in the sentence. That means we can not get the sementics of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF** - It stands for Term Frequency - Inverse Document Frequency\n",
    "<br> To get embedding with TF-IDF, we calculate Term frequency and Inverse Document Frequency seperate and then multiply them together to get TF-IDF.\n",
    "Formulas to calculate TF-IDF: \n",
    "<br>\n",
    "<br>**TF :**  $$\\frac{Number\\, of\\, repetition\\, of\\, word\\, in\\, a\\, sentence}{Number\\, of\\, words\\, in\\, a\\, sentence}$$ \n",
    "**IDF :**$$log\\Bigg[\\frac{Total\\, Number\\, of\\,sentences}{Number\\, of\\, sentences\\, containing\\, the \\, word}\\Bigg]$$ \n",
    "<br>\n",
    "**TF-IDF :** $TF * IDF$ $$\\Bigg[\\frac{Number\\, of\\, repetition\\, of\\, word\\, in\\, a\\, sentence}{Number\\, of\\, words\\, in\\, a\\, sentence}\\Bigg]*log\\Bigg[\\frac{Total\\, Number\\, of\\,sentences}{Number\\, of\\, sentences\\, containing\\, the \\, word}\\Bigg]$$ \n",
    "<br>In **TF-IDF** also, we create dictionary of words with their count of occurance. **TF** assign more weightage to the word which repeat multiple times in the sentance where as **IDF** decreases the weightage to word as number of sentences containing the increases. Here, feature vectors not only contains 0's and 1' but does contain other values depending on the significance of the word in the sentence. This technique retains the sementics of the sentence to some extent so it should perform better than BOW.\n",
    "<br>Here **TF-IDG** can have zero value for the word which existed in every sentence and give more weightage to least occured words that means it could cause over-fitting problem but that is yet to discove. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try Bag-of-Words and TF-IDFto get our features for `X_train`  and `X_test` data. The resultant embeddings are in numpy array format, if we have a look at the the embeddings we will know it is high dimensional sparse data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix used to evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-label classification problems must be assessed using different performance measures than single-label classification problems.\n",
    "<br>\n",
    "<br>\n",
    "Jaccard similarity, or the Jaccard index, is the size of the intersection of the predicted labels and the true labels divided by the size of the union of the predicted and true labels. It ranges from 0 to 1, and 1 is the perfect score.Here we are taking mean so 100 is perfect score. This function can be imported from *Sklearn.metrics* but just to have better usderstanding we are defining the `j_score` function.\n",
    "<br>\n",
    "<br>\n",
    "We will also look at *F1-score* and *ROC score*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models we are using for text classification\n",
    "1. Logistics Regression\n",
    "2. Naive Bayes (NB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model to use?\n",
    "<br>\n",
    "Which is the fastest model for high dimensional sparse data?  - **Logistic regression**\n",
    "<br>We will use Logistic regression for this dataset to start with and the solver we are using is 'sag' as it is faster for large datsets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Logistic regression is similar to `Linear Regression` except it predicts whether something is **True** or **False**, instead of predicting a continuous value. Also instead of fitting a line to the data it fits an **\"S\"** shaped \"logistic function\" which is called `sigmoid function`.\n",
    "<br> In `Logistic Regression ` we don't need to do much to classify an instance. All we have to do is calculate the sigmoid of the vectorunder test multiplied by the weights optimized. If sigmoid gives a value greater than 0.5 the class is 1 and it is 0 otherwise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training LogisticRegression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  LogisticRegression\n",
      "Jaccard score: 2.4208497375328086\n",
      "F1 Score : 0.05396290560876806\n",
      "None\n",
      "Accuracy is 0.8986538991803074\n",
      "ROC_AUC - 0.514002011361763\n",
      "check model accuracy on input_string [[0 0 0 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[36071     7]\n",
      "  [ 3620   195]]\n",
      "\n",
      " [[39482     5]\n",
      "  [  390    16]]\n",
      "\n",
      " [[37741     9]\n",
      "  [ 2053    90]]\n",
      "\n",
      " [[39788     0]\n",
      "  [  104     1]]\n",
      "\n",
      " [[37873     9]\n",
      "  [ 1974    37]]\n",
      "\n",
      " [[39535     1]\n",
      "  [  354     3]]]\n"
     ]
    }
   ],
   "source": [
    "lr_clf, lr_vectorizer, lr_sumry = train_model(logreg, corpus, df[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression(solver='sag')</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.898654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard score</th>\n",
       "      <td>2.420850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_score</th>\n",
       "      <td>0.053963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_score</th>\n",
       "      <td>0.514002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LogisticRegression(solver='sag')\n",
       "accuracy                               0.898654\n",
       "jaccard score                          2.420850\n",
       "F1_score                               0.053963\n",
       "roc_score                              0.514002"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_lr = pd.DataFrame(lr_sumry, index = ['accuracy', 'jaccard score', 'F1_score', 'roc_score'], \n",
    "                          columns= [lr_clf.estimators_[0]])\n",
    "summary_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a classifier under supervised ML group based on probalistic logic. Probabilistic logic it uses is  `Bayes Theorem`  which gives probability of an event based on prior knowledge of condition that might be related to event\n",
    "<br>\n",
    "<br>\n",
    "**P(Class|Features) :**  $$\\frac{P(Features|Class) * P(Class)}{P(Features)}$$ \n",
    "It assumes that the probability of a one word doesn't depends on any other word in the document. We know this is unrealistic. That's why it is known as `naive Bayes`. Despite of its incorrect assumptions, `naive Bayes` is effective at classification. \n",
    "<br>Moreover, assuming conditional independence among the features in the dataset, it reduces the need of large training data.\n",
    "#### Multinomial NB\n",
    "In our use case we will be using this `Multinomial NB` because it assumes count data which means each feature represents an integer count of some-thing, in our problem it is that how often a word appears in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bayes = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training MultinomialNB model\n",
      "... Computing accuracy\n",
      "... Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  MultinomialNB\n",
      "Jaccard score: 34.340896239751125\n",
      "F1 Score : 0.49689026569064043\n",
      "None\n",
      "Accuracy is 0.8983029604191212\n",
      "ROC_AUC - 0.786800037695929\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[35348   730]\n",
      "  [ 1474  2341]]\n",
      "\n",
      " [[38980   507]\n",
      "  [  130   276]]\n",
      "\n",
      " [[37240   510]\n",
      "  [  673  1470]]\n",
      "\n",
      " [[39444   344]\n",
      "  [   52    53]]\n",
      "\n",
      " [[37163   719]\n",
      "  [  810  1201]]\n",
      "\n",
      " [[38993   543]\n",
      "  [  197   160]]]\n"
     ]
    }
   ],
   "source": [
    "nb_clf, nb_vectorizer, nb_sumry = train_model(n_bayes, corpus, df[labels] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultinomialNB()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.898303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard score</th>\n",
       "      <td>34.340896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_score</th>\n",
       "      <td>0.496890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_score</th>\n",
       "      <td>0.786800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MultinomialNB()\n",
       "accuracy              0.898303\n",
       "jaccard score        34.340896\n",
       "F1_score              0.496890\n",
       "roc_score             0.786800"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_nb = pd.DataFrame(nb_sumry, index = ['accuracy', 'jaccard score', 'F1_score', 'roc_score'],\n",
    "                          columns= [nb_clf.estimators_[0]])\n",
    "summary_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "**Naive Bayes or Logistic regression !!**\n",
    "<br>Compairing the confusion matrixs and Jaccard score, Naive Bayes clearly out performed Linear regression and Naive Bayes even tends to get trained faster.\n",
    "Just yet we can't decide, we need to try different model evaluation techniqes first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K FOLD Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - K Fold cross validation with Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use GridSearchCV to evaluate the model using different values of **C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"estimator__C\": [0.001, 0.01, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Performing train test split\n"
     ]
    }
   ],
   "source": [
    "#Train-test split\n",
    "print(\"... Performing train test split\")\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(corpus,df[labels],\n",
    "                                                                    test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Extracting features\n"
     ]
    }
   ],
   "source": [
    "## Features extraction with word embedding\n",
    "print(\"... Extracting features\")\n",
    "Xv_train, Xv_test, vectorizer = get_embeddings(X_train, X_test,\n",
    "                                                          max_feature = 1000 , embedding_type= 'bow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to reproduce results\n",
    "clf_lr = OneVsRestClassifier(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to reproduce results\n",
    "gs_lr = GridSearchCV(clf_lr, param_grid ,scoring = 'f1_micro', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run GridSerch with K-fold cross validation\n",
    "gs_lr.fit(Xv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the best estimator : 0.0742671009771987\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score of the best estimator : {}\".format(gs_lr.score(Xv_test, y_test )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator is : OneVsRestClassifier(estimator=LogisticRegression(C=0.1, solver='sag'))\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator is : {}\".format(gs_lr.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "As we can see that *Logistic Regression* performed well with **C = 0.1** on 3 Folds of cross validation. We will use this value of **C** with the various combination of *maximum_features* and *embedding types* in next part to check the performance of *Logistic Regression* during the best model selection process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "#### Naive Bayes - K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Cross Validation score = [0.8985787  0.89827789 0.89804973]\n"
     ]
    }
   ],
   "source": [
    "### Naive bayes\n",
    "nbayes = OneVsRestClassifier(naive_bayes.MultinomialNB())\n",
    "nbayes.fit(Xv_train, y_train)\n",
    "cv_score= cross_val_score(nbayes,Xv_train,y_train,cv=3)\n",
    "print('Naive Bayes Cross Validation score = {}'.format(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We can see even with the K-fold cross validation *Naive Bayes* is giving consistant results for the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='sag', C= 0.1)\n",
    "classifier = [logreg, n_bayes]\n",
    "max_feature = [1200, 1500, 1700, 2000]\n",
    "embedding= ['bow', 'tfidf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training models with all different combinations of the parameters stated in above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... Processing LogisticRegression(C=0.1, solver='sag')\n",
      ".... Combination 1200, bow \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training LogisticRegression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  LogisticRegression\n",
      "Jaccard score: 2.4405347769028873\n",
      "F1 Score : 0.05424650879849518\n",
      "None\n",
      "Accuracy is 0.8986538991803074\n",
      "ROC_AUC - 0.5140798836765966\n",
      "check model accuracy on input_string [[0 0 0 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[36071     7]\n",
      "  [ 3620   195]]\n",
      "\n",
      " [[39482     5]\n",
      "  [  390    16]]\n",
      "\n",
      " [[37742     8]\n",
      "  [ 2051    92]]\n",
      "\n",
      " [[39788     0]\n",
      "  [  104     1]]\n",
      "\n",
      " [[37873     9]\n",
      "  [ 1974    37]]\n",
      "\n",
      " [[39534     2]\n",
      "  [  354     3]]]\n",
      ".... Combination 1200, tfidf \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training LogisticRegression model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  LogisticRegression\n",
      "Jaccard score: 30.15339663988314\n",
      "F1 Score : 0.3453158479919651\n",
      "None\n",
      "Accuracy is 0.9127165166821247\n",
      "ROC_AUC - 0.6244354518201726\n",
      "check model accuracy on input_string [[1 0 0 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[36007    71]\n",
      "  [ 2078  1737]]\n",
      "\n",
      " [[39446    41]\n",
      "  [  343    63]]\n",
      "\n",
      " [[37690    60]\n",
      "  [ 1071  1072]]\n",
      "\n",
      " [[39788     0]\n",
      "  [  105     0]]\n",
      "\n",
      " [[37734   148]\n",
      "  [ 1264   747]]\n",
      "\n",
      " [[39534     2]\n",
      "  [  350     7]]]\n",
      ".... Combination 1500, bow \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training LogisticRegression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  LogisticRegression\n",
      "Jaccard score: 2.5090223097112863\n",
      "F1 Score : 0.05499686661789316\n",
      "None\n",
      "Accuracy is 0.8987040332890482\n",
      "ROC_AUC - 0.5142739489194659\n",
      "check model accuracy on input_string [[0 0 0 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[36071     7]\n",
      "  [ 3617   198]]\n",
      "\n",
      " [[39483     4]\n",
      "  [  390    16]]\n",
      "\n",
      " [[37742     8]\n",
      "  [ 2051    92]]\n",
      "\n",
      " [[39788     0]\n",
      "  [  104     1]]\n",
      "\n",
      " [[37873     9]\n",
      "  [ 1971    40]]\n",
      "\n",
      " [[39535     1]\n",
      "  [  354     3]]]\n",
      ".... Combination 1500, tfidf \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training LogisticRegression model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  LogisticRegression\n",
      "Jaccard score: 30.103963612735544\n",
      "F1 Score : 0.34236089482335696\n",
      "None\n",
      "Accuracy is 0.9126663825733838\n",
      "ROC_AUC - 0.6232057010257515\n",
      "check model accuracy on input_string [[1 0 0 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[36010    68]\n",
      "  [ 2071  1744]]\n",
      "\n",
      " [[39438    49]\n",
      "  [  345    61]]\n",
      "\n",
      " [[37693    57]\n",
      "  [ 1093  1050]]\n",
      "\n",
      " [[39788     0]\n",
      "  [  105     0]]\n",
      "\n",
      " [[37739   143]\n",
      "  [ 1267   744]]\n",
      "\n",
      " [[39534     2]\n",
      "  [  350     7]]]\n",
      ".... Combination 1700, bow \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training LogisticRegression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  LogisticRegression\n",
      "Jaccard score: 2.523786089238846\n",
      "F1 Score : 0.055999042728626915\n",
      "None\n",
      "Accuracy is 0.8987291003434187\n",
      "ROC_AUC - 0.5145313270069294\n",
      "check model accuracy on input_string [[0 0 0 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[36071     7]\n",
      "  [ 3616   199]]\n",
      "\n",
      " [[39483     4]\n",
      "  [  390    16]]\n",
      "\n",
      " [[37742     8]\n",
      "  [ 2051    92]]\n",
      "\n",
      " [[39788     0]\n",
      "  [  104     1]]\n",
      "\n",
      " [[37873     9]\n",
      "  [ 1971    40]]\n",
      "\n",
      " [[39536     0]\n",
      "  [  353     4]]]\n",
      ".... Combination 1700, tfidf \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training LogisticRegression model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  LogisticRegression\n",
      "Jaccard score: 29.919413919413945\n",
      "F1 Score : 0.33755166106456674\n",
      "None\n",
      "Accuracy is 0.9124658461384203\n",
      "ROC_AUC - 0.6211262166735317\n",
      "check model accuracy on input_string [[1 0 0 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[36020    58]\n",
      "  [ 2077  1738]]\n",
      "\n",
      " [[39440    47]\n",
      "  [  349    57]]\n",
      "\n",
      " [[37696    54]\n",
      "  [ 1102  1041]]\n",
      "\n",
      " [[39788     0]\n",
      "  [  105     0]]\n",
      "\n",
      " [[37740   142]\n",
      "  [ 1281   730]]\n",
      "\n",
      " [[39534     2]\n",
      "  [  351     6]]]\n",
      ".... Combination 2000, bow \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training LogisticRegression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  LogisticRegression\n",
      "Jaccard score: 2.5352690288713915\n",
      "F1 Score : 0.05614149422955315\n",
      "None\n",
      "Accuracy is 0.8987291003434187\n",
      "ROC_AUC - 0.5145702133033986\n",
      "check model accuracy on input_string [[0 0 0 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[36071     7]\n",
      "  [ 3616   199]]\n",
      "\n",
      " [[39483     4]\n",
      "  [  390    16]]\n",
      "\n",
      " [[37742     8]\n",
      "  [ 2050    93]]\n",
      "\n",
      " [[39788     0]\n",
      "  [  104     1]]\n",
      "\n",
      " [[37873     9]\n",
      "  [ 1971    40]]\n",
      "\n",
      " [[39536     0]\n",
      "  [  353     4]]]\n",
      ".... Combination 2000, tfidf \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training LogisticRegression model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  LogisticRegression\n",
      "Jaccard score: 29.527241632054736\n",
      "F1 Score : 0.33246160601041497\n",
      "None\n",
      "Accuracy is 0.9124658461384203\n",
      "ROC_AUC - 0.6187219763849033\n",
      "check model accuracy on input_string [[1 0 0 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[36023    55]\n",
      "  [ 2095  1720]]\n",
      "\n",
      " [[39447    40]\n",
      "  [  353    53]]\n",
      "\n",
      " [[37698    52]\n",
      "  [ 1116  1027]]\n",
      "\n",
      " [[39788     0]\n",
      "  [  105     0]]\n",
      "\n",
      " [[37747   135]\n",
      "  [ 1292   719]]\n",
      "\n",
      " [[39535     1]\n",
      "  [  352     5]]]\n",
      ".... Processing MultinomialNB()\n",
      ".... Combination 1200, bow \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training MultinomialNB model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  MultinomialNB\n",
      "Jaccard score: 35.01624637988262\n",
      "F1 Score : 0.4976753230824767\n",
      "None\n",
      "Accuracy is 0.8986789662346778\n",
      "ROC_AUC - 0.7907089104329962\n",
      "check model accuracy on input_string [[1 1 1 1 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[35349   729]\n",
      "  [ 1424  2391]]\n",
      "\n",
      " [[38973   514]\n",
      "  [  132   274]]\n",
      "\n",
      " [[37227   523]\n",
      "  [  651  1492]]\n",
      "\n",
      " [[39423   365]\n",
      "  [   52    53]]\n",
      "\n",
      " [[37145   737]\n",
      "  [  787  1224]]\n",
      "\n",
      " [[38950   586]\n",
      "  [  190   167]]]\n",
      ".... Combination 1200, tfidf \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training MultinomialNB model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  MultinomialNB\n",
      "Jaccard score: 31.52686868686867\n",
      "F1 Score : 0.4138414861341304\n",
      "None\n",
      "Accuracy is 0.9136189306394605\n",
      "ROC_AUC - 0.6547830241068736\n",
      "check model accuracy on input_string [[1 0 0 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[35976   102]\n",
      "  [ 2031  1784]]\n",
      "\n",
      " [[39385   102]\n",
      "  [  277   129]]\n",
      "\n",
      " [[37659    91]\n",
      "  [ 1023  1120]]\n",
      "\n",
      " [[39787     1]\n",
      "  [  104     1]]\n",
      "\n",
      " [[37695   187]\n",
      "  [ 1151   860]]\n",
      "\n",
      " [[39495    41]\n",
      "  [  312    45]]]\n",
      ".... Combination 1500, bow \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training MultinomialNB model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  MultinomialNB\n",
      "Jaccard score: 35.42920847268661\n",
      "F1 Score : 0.49572859493244364\n",
      "None\n",
      "Accuracy is 0.8973504123530444\n",
      "ROC_AUC - 0.7957911084630872\n",
      "check model accuracy on input_string [[1 1 1 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[35279   799]\n",
      "  [ 1351  2464]]\n",
      "\n",
      " [[38951   536]\n",
      "  [  127   279]]\n",
      "\n",
      " [[37163   587]\n",
      "  [  632  1511]]\n",
      "\n",
      " [[39392   396]\n",
      "  [   52    53]]\n",
      "\n",
      " [[37085   797]\n",
      "  [  736  1275]]\n",
      "\n",
      " [[38913   623]\n",
      "  [  189   168]]]\n",
      ".... Combination 1500, tfidf \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training MultinomialNB model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  MultinomialNB\n",
      "Jaccard score: 32.4953759549658\n",
      "F1 Score : 0.4094496411128184\n",
      "None\n",
      "Accuracy is 0.9137944000200536\n",
      "ROC_AUC - 0.6540509782111444\n",
      "check model accuracy on input_string [[1 0 0 0 0 0]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[35956   122]\n",
      "  [ 1959  1856]]\n",
      "\n",
      " [[39392    95]\n",
      "  [  280   126]]\n",
      "\n",
      " [[37654    96]\n",
      "  [ 1013  1130]]\n",
      "\n",
      " [[39787     1]\n",
      "  [  105     0]]\n",
      "\n",
      " [[37688   194]\n",
      "  [ 1147   864]]\n",
      "\n",
      " [[39499    37]\n",
      "  [  318    39]]]\n",
      ".... Combination 1700, bow \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training MultinomialNB model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  MultinomialNB\n",
      "Jaccard score: 35.99999999999985\n",
      "F1 Score : 0.5002719573121386\n",
      "None\n",
      "Accuracy is 0.8977013511142306\n",
      "ROC_AUC - 0.8013863149233699\n",
      "check model accuracy on input_string [[1 1 1 1 1 1]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[35282   796]\n",
      "  [ 1315  2500]]\n",
      "\n",
      " [[38947   540]\n",
      "  [  125   281]]\n",
      "\n",
      " [[37150   600]\n",
      "  [  619  1524]]\n",
      "\n",
      " [[39383   405]\n",
      "  [   51    54]]\n",
      "\n",
      " [[37074   808]\n",
      "  [  721  1290]]\n",
      "\n",
      " [[38905   631]\n",
      "  [  178   179]]]\n",
      ".... Combination 1700, tfidf \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training MultinomialNB model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  MultinomialNB\n",
      "Jaccard score: 32.99045556624958\n",
      "F1 Score : 0.4127106624875891\n",
      "None\n",
      "Accuracy is 0.9135186624219788\n",
      "ROC_AUC - 0.6557974012505531\n",
      "check model accuracy on input_string [[1 0 1 0 1 1]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[35942   136]\n",
      "  [ 1918  1897]]\n",
      "\n",
      " [[39396    91]\n",
      "  [  284   122]]\n",
      "\n",
      " [[37641   109]\n",
      "  [  999  1144]]\n",
      "\n",
      " [[39787     1]\n",
      "  [  105     0]]\n",
      "\n",
      " [[37681   201]\n",
      "  [ 1135   876]]\n",
      "\n",
      " [[39498    38]\n",
      "  [  315    42]]]\n",
      ".... Combination 2000, bow \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training MultinomialNB model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  MultinomialNB\n",
      "Jaccard score: 36.21117365019788\n",
      "F1 Score : 0.503718602592237\n",
      "None\n",
      "Accuracy is 0.8976512170054897\n",
      "ROC_AUC - 0.8070323089999197\n",
      "check model accuracy on input_string [[1 1 1 1 1 1]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[35269   809]\n",
      "  [ 1290  2525]]\n",
      "\n",
      " [[38955   532]\n",
      "  [  120   286]]\n",
      "\n",
      " [[37127   623]\n",
      "  [  612  1531]]\n",
      "\n",
      " [[39371   417]\n",
      "  [   49    56]]\n",
      "\n",
      " [[37065   817]\n",
      "  [  703  1308]]\n",
      "\n",
      " [[38878   658]\n",
      "  [  171   186]]]\n",
      ".... Combination 2000, tfidf \n",
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training MultinomialNB model\n",
      "...Computing accuracy\n",
      "...Saving model in model directory\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  MultinomialNB\n",
      "Jaccard score: 33.37903937134148\n",
      "F1 Score : 0.41141525054401246\n",
      "None\n",
      "Accuracy is 0.9136690647482014\n",
      "ROC_AUC - 0.6559499675048147\n",
      "check model accuracy on input_string [[1 0 1 0 1 1]]\n",
      "None\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[35939   139]\n",
      "  [ 1900  1915]]\n",
      "\n",
      " [[39397    90]\n",
      "  [  286   120]]\n",
      "\n",
      " [[37636   114]\n",
      "  [  989  1154]]\n",
      "\n",
      " [[39787     1]\n",
      "  [  105     0]]\n",
      "\n",
      " [[37675   207]\n",
      "  [ 1117   894]]\n",
      "\n",
      " [[39497    39]\n",
      "  [  319    38]]]\n",
      "[[0.8986538991803074, 2.4405347769028873, 0.05424650879849518, 0.5140798836765966], [0.9127165166821247, 30.15339663988314, 0.3453158479919651, 0.6244354518201726], [0.8987040332890482, 2.5090223097112863, 0.05499686661789316, 0.5142739489194659], [0.9126663825733838, 30.103963612735544, 0.34236089482335696, 0.6232057010257515], [0.8987291003434187, 2.523786089238846, 0.055999042728626915, 0.5145313270069294], [0.9124658461384203, 29.919413919413945, 0.33755166106456674, 0.6211262166735317], [0.8987291003434187, 2.5352690288713915, 0.05614149422955315, 0.5145702133033986], [0.9124658461384203, 29.527241632054736, 0.33246160601041497, 0.6187219763849033], [0.8986789662346778, 35.01624637988262, 0.4976753230824767, 0.7907089104329962], [0.9136189306394605, 31.52686868686867, 0.4138414861341304, 0.6547830241068736], [0.8973504123530444, 35.42920847268661, 0.49572859493244364, 0.7957911084630872], [0.9137944000200536, 32.4953759549658, 0.4094496411128184, 0.6540509782111444], [0.8977013511142306, 35.99999999999985, 0.5002719573121386, 0.8013863149233699], [0.9135186624219788, 32.99045556624958, 0.4127106624875891, 0.6557974012505531], [0.8976512170054897, 36.21117365019788, 0.503718602592237, 0.8070323089999197], [0.9136690647482014, 33.37903937134148, 0.41141525054401246, 0.6559499675048147]]\n",
      "{'classifier': 'OneVsRestClassifier', 'max_features': 2000, 'embedding_type': 'bow'}\n"
     ]
    }
   ],
   "source": [
    "summary_report =  []\n",
    "combinations =[]\n",
    "best_jscore = 1\n",
    "for estimator in classifier:\n",
    "  print(\".... Processing {}\".format(estimator))\n",
    "  for m in max_feature:\n",
    "    for n in embedding:\n",
    "      print(\".... Combination {}, {} \".format(m,n))\n",
    "      combinations.append((estimator.__class__.__name__, m, n))\n",
    "      clf, vectorizer, score_sumry = train_model(estimator, corpus, df[labels], max_feature=m, embedding= n )\n",
    "      summary_report.append(score_sumry)\n",
    "      if score_sumry[1] > best_jscore:\n",
    "        best_jscore =score_sumry[1]\n",
    "        best_param = {\"classifier\": clf.__class__.__name__, \"max_features\": m, \"embedding_type\":n}\n",
    "      \n",
    "      \n",
    "print(summary_report)\n",
    "print(best_param)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Summary of all the Models Trained on different sets of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>jaccard score</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>roc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1200, bow)</th>\n",
       "      <td>0.898654</td>\n",
       "      <td>2.440535</td>\n",
       "      <td>0.054247</td>\n",
       "      <td>0.514080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1200, tfidf)</th>\n",
       "      <td>0.912717</td>\n",
       "      <td>30.153397</td>\n",
       "      <td>0.345316</td>\n",
       "      <td>0.624435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1500, bow)</th>\n",
       "      <td>0.898704</td>\n",
       "      <td>2.509022</td>\n",
       "      <td>0.054997</td>\n",
       "      <td>0.514274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1500, tfidf)</th>\n",
       "      <td>0.912666</td>\n",
       "      <td>30.103964</td>\n",
       "      <td>0.342361</td>\n",
       "      <td>0.623206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1700, bow)</th>\n",
       "      <td>0.898729</td>\n",
       "      <td>2.523786</td>\n",
       "      <td>0.055999</td>\n",
       "      <td>0.514531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1700, tfidf)</th>\n",
       "      <td>0.912466</td>\n",
       "      <td>29.919414</td>\n",
       "      <td>0.337552</td>\n",
       "      <td>0.621126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 2000, bow)</th>\n",
       "      <td>0.898729</td>\n",
       "      <td>2.535269</td>\n",
       "      <td>0.056141</td>\n",
       "      <td>0.514570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 2000, tfidf)</th>\n",
       "      <td>0.912466</td>\n",
       "      <td>29.527242</td>\n",
       "      <td>0.332462</td>\n",
       "      <td>0.618722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1200, bow)</th>\n",
       "      <td>0.898679</td>\n",
       "      <td>35.016246</td>\n",
       "      <td>0.497675</td>\n",
       "      <td>0.790709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1200, tfidf)</th>\n",
       "      <td>0.913619</td>\n",
       "      <td>31.526869</td>\n",
       "      <td>0.413841</td>\n",
       "      <td>0.654783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1500, bow)</th>\n",
       "      <td>0.897350</td>\n",
       "      <td>35.429208</td>\n",
       "      <td>0.495729</td>\n",
       "      <td>0.795791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1500, tfidf)</th>\n",
       "      <td>0.913794</td>\n",
       "      <td>32.495376</td>\n",
       "      <td>0.409450</td>\n",
       "      <td>0.654051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1700, bow)</th>\n",
       "      <td>0.897701</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.500272</td>\n",
       "      <td>0.801386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1700, tfidf)</th>\n",
       "      <td>0.913519</td>\n",
       "      <td>32.990456</td>\n",
       "      <td>0.412711</td>\n",
       "      <td>0.655797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 2000, bow)</th>\n",
       "      <td>0.897651</td>\n",
       "      <td>36.211174</td>\n",
       "      <td>0.503719</td>\n",
       "      <td>0.807032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 2000, tfidf)</th>\n",
       "      <td>0.913669</td>\n",
       "      <td>33.379039</td>\n",
       "      <td>0.411415</td>\n",
       "      <td>0.655950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   accuracy  jaccard score  F1_score  \\\n",
       "(LogisticRegression, 1200, bow)    0.898654       2.440535  0.054247   \n",
       "(LogisticRegression, 1200, tfidf)  0.912717      30.153397  0.345316   \n",
       "(LogisticRegression, 1500, bow)    0.898704       2.509022  0.054997   \n",
       "(LogisticRegression, 1500, tfidf)  0.912666      30.103964  0.342361   \n",
       "(LogisticRegression, 1700, bow)    0.898729       2.523786  0.055999   \n",
       "(LogisticRegression, 1700, tfidf)  0.912466      29.919414  0.337552   \n",
       "(LogisticRegression, 2000, bow)    0.898729       2.535269  0.056141   \n",
       "(LogisticRegression, 2000, tfidf)  0.912466      29.527242  0.332462   \n",
       "(MultinomialNB, 1200, bow)         0.898679      35.016246  0.497675   \n",
       "(MultinomialNB, 1200, tfidf)       0.913619      31.526869  0.413841   \n",
       "(MultinomialNB, 1500, bow)         0.897350      35.429208  0.495729   \n",
       "(MultinomialNB, 1500, tfidf)       0.913794      32.495376  0.409450   \n",
       "(MultinomialNB, 1700, bow)         0.897701      36.000000  0.500272   \n",
       "(MultinomialNB, 1700, tfidf)       0.913519      32.990456  0.412711   \n",
       "(MultinomialNB, 2000, bow)         0.897651      36.211174  0.503719   \n",
       "(MultinomialNB, 2000, tfidf)       0.913669      33.379039  0.411415   \n",
       "\n",
       "                                   roc_score  \n",
       "(LogisticRegression, 1200, bow)     0.514080  \n",
       "(LogisticRegression, 1200, tfidf)   0.624435  \n",
       "(LogisticRegression, 1500, bow)     0.514274  \n",
       "(LogisticRegression, 1500, tfidf)   0.623206  \n",
       "(LogisticRegression, 1700, bow)     0.514531  \n",
       "(LogisticRegression, 1700, tfidf)   0.621126  \n",
       "(LogisticRegression, 2000, bow)     0.514570  \n",
       "(LogisticRegression, 2000, tfidf)   0.618722  \n",
       "(MultinomialNB, 1200, bow)          0.790709  \n",
       "(MultinomialNB, 1200, tfidf)        0.654783  \n",
       "(MultinomialNB, 1500, bow)          0.795791  \n",
       "(MultinomialNB, 1500, tfidf)        0.654051  \n",
       "(MultinomialNB, 1700, bow)          0.801386  \n",
       "(MultinomialNB, 1700, tfidf)        0.655797  \n",
       "(MultinomialNB, 2000, bow)          0.807032  \n",
       "(MultinomialNB, 2000, tfidf)        0.655950  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_r = pd.DataFrame(summary_report, index = [combinations], columns= ['accuracy', 'jaccard score', 'F1_score', 'roc_score'],)\n",
    "summary_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>jaccard score</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>roc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 2000, bow)</th>\n",
       "      <td>0.897651</td>\n",
       "      <td>36.211174</td>\n",
       "      <td>0.503719</td>\n",
       "      <td>0.807032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1700, bow)</th>\n",
       "      <td>0.897701</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.500272</td>\n",
       "      <td>0.801386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1500, bow)</th>\n",
       "      <td>0.897350</td>\n",
       "      <td>35.429208</td>\n",
       "      <td>0.495729</td>\n",
       "      <td>0.795791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1200, bow)</th>\n",
       "      <td>0.898679</td>\n",
       "      <td>35.016246</td>\n",
       "      <td>0.497675</td>\n",
       "      <td>0.790709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 2000, tfidf)</th>\n",
       "      <td>0.913669</td>\n",
       "      <td>33.379039</td>\n",
       "      <td>0.411415</td>\n",
       "      <td>0.655950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1700, tfidf)</th>\n",
       "      <td>0.913519</td>\n",
       "      <td>32.990456</td>\n",
       "      <td>0.412711</td>\n",
       "      <td>0.655797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1500, tfidf)</th>\n",
       "      <td>0.913794</td>\n",
       "      <td>32.495376</td>\n",
       "      <td>0.409450</td>\n",
       "      <td>0.654051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(MultinomialNB, 1200, tfidf)</th>\n",
       "      <td>0.913619</td>\n",
       "      <td>31.526869</td>\n",
       "      <td>0.413841</td>\n",
       "      <td>0.654783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1200, tfidf)</th>\n",
       "      <td>0.912717</td>\n",
       "      <td>30.153397</td>\n",
       "      <td>0.345316</td>\n",
       "      <td>0.624435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1500, tfidf)</th>\n",
       "      <td>0.912666</td>\n",
       "      <td>30.103964</td>\n",
       "      <td>0.342361</td>\n",
       "      <td>0.623206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1700, tfidf)</th>\n",
       "      <td>0.912466</td>\n",
       "      <td>29.919414</td>\n",
       "      <td>0.337552</td>\n",
       "      <td>0.621126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 2000, tfidf)</th>\n",
       "      <td>0.912466</td>\n",
       "      <td>29.527242</td>\n",
       "      <td>0.332462</td>\n",
       "      <td>0.618722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 2000, bow)</th>\n",
       "      <td>0.898729</td>\n",
       "      <td>2.535269</td>\n",
       "      <td>0.056141</td>\n",
       "      <td>0.514570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1700, bow)</th>\n",
       "      <td>0.898729</td>\n",
       "      <td>2.523786</td>\n",
       "      <td>0.055999</td>\n",
       "      <td>0.514531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1500, bow)</th>\n",
       "      <td>0.898704</td>\n",
       "      <td>2.509022</td>\n",
       "      <td>0.054997</td>\n",
       "      <td>0.514274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(LogisticRegression, 1200, bow)</th>\n",
       "      <td>0.898654</td>\n",
       "      <td>2.440535</td>\n",
       "      <td>0.054247</td>\n",
       "      <td>0.514080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   accuracy  jaccard score  F1_score  \\\n",
       "(MultinomialNB, 2000, bow)         0.897651      36.211174  0.503719   \n",
       "(MultinomialNB, 1700, bow)         0.897701      36.000000  0.500272   \n",
       "(MultinomialNB, 1500, bow)         0.897350      35.429208  0.495729   \n",
       "(MultinomialNB, 1200, bow)         0.898679      35.016246  0.497675   \n",
       "(MultinomialNB, 2000, tfidf)       0.913669      33.379039  0.411415   \n",
       "(MultinomialNB, 1700, tfidf)       0.913519      32.990456  0.412711   \n",
       "(MultinomialNB, 1500, tfidf)       0.913794      32.495376  0.409450   \n",
       "(MultinomialNB, 1200, tfidf)       0.913619      31.526869  0.413841   \n",
       "(LogisticRegression, 1200, tfidf)  0.912717      30.153397  0.345316   \n",
       "(LogisticRegression, 1500, tfidf)  0.912666      30.103964  0.342361   \n",
       "(LogisticRegression, 1700, tfidf)  0.912466      29.919414  0.337552   \n",
       "(LogisticRegression, 2000, tfidf)  0.912466      29.527242  0.332462   \n",
       "(LogisticRegression, 2000, bow)    0.898729       2.535269  0.056141   \n",
       "(LogisticRegression, 1700, bow)    0.898729       2.523786  0.055999   \n",
       "(LogisticRegression, 1500, bow)    0.898704       2.509022  0.054997   \n",
       "(LogisticRegression, 1200, bow)    0.898654       2.440535  0.054247   \n",
       "\n",
       "                                   roc_score  \n",
       "(MultinomialNB, 2000, bow)          0.807032  \n",
       "(MultinomialNB, 1700, bow)          0.801386  \n",
       "(MultinomialNB, 1500, bow)          0.795791  \n",
       "(MultinomialNB, 1200, bow)          0.790709  \n",
       "(MultinomialNB, 2000, tfidf)        0.655950  \n",
       "(MultinomialNB, 1700, tfidf)        0.655797  \n",
       "(MultinomialNB, 1500, tfidf)        0.654051  \n",
       "(MultinomialNB, 1200, tfidf)        0.654783  \n",
       "(LogisticRegression, 1200, tfidf)   0.624435  \n",
       "(LogisticRegression, 1500, tfidf)   0.623206  \n",
       "(LogisticRegression, 1700, tfidf)   0.621126  \n",
       "(LogisticRegression, 2000, tfidf)   0.618722  \n",
       "(LogisticRegression, 2000, bow)     0.514570  \n",
       "(LogisticRegression, 1700, bow)     0.514531  \n",
       "(LogisticRegression, 1500, bow)     0.514274  \n",
       "(LogisticRegression, 1200, bow)     0.514080  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_all_combinations = summary_r.sort_values(by=['jaccard score'],ascending=False)\n",
    "summary_all_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with **C =0.1** logistic regression is doing much worst that **C= 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its evident from above results that *Logistic Regression* perform well with continuous data (when features were computed with \"TF-IDF\") and *Naive Bayes* do good when data is in discrete form (When features were computer with \"Bag-of Words\"). Considering *Jaccard score*, *F1-score*, and *ROC_AUC score* **Naive Bayes** perform well, though when we train *Logistic Regression* with **C=1**, it does perform better than *Naive Bayes* only in terms of *Jaccard score*. I am sure with further fine tuning of the hyper parameters, we could get good *Logistic Regression* Model but its is quite expensive to get there in terms of computations and time. So we will go with **Naive Bayes** using *\"Bag-of-Words\"* embedding technique with *max_features* count as 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Performing train test split\n",
      "... Extracting features\n",
      "... Training MultinomialNB model\n",
      "... Computing accuracy\n",
      "\n",
      "\n",
      "Model evaluation\n",
      "------\n",
      "Clf:  MultinomialNB\n",
      "Jaccard score: 36.21117365019788\n",
      "F1 Score : 0.503718602592237\n",
      "None\n",
      "Accuracy is 0.8976512170054897\n",
      "ROC_AUC - 0.8070323089999197\n",
      "------\n",
      "Multilabel confusion matrix \n",
      " [[[35269   809]\n",
      "  [ 1290  2525]]\n",
      "\n",
      " [[38955   532]\n",
      "  [  120   286]]\n",
      "\n",
      " [[37127   623]\n",
      "  [  612  1531]]\n",
      "\n",
      " [[39371   417]\n",
      "  [   49    56]]\n",
      "\n",
      " [[37065   817]\n",
      "  [  703  1308]]\n",
      "\n",
      " [[38878   658]\n",
      "  [  171   186]]]\n"
     ]
    }
   ],
   "source": [
    "final_clf, final_vectorizer , model_summary = train_model(n_bayes, corpus, df[labels], max_feature=2000, embedding= \"bow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultinomialNB()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.897651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard score</th>\n",
       "      <td>36.211174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_score</th>\n",
       "      <td>0.503719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_score</th>\n",
       "      <td>0.807032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MultinomialNB()\n",
       "accuracy              0.897651\n",
       "jaccard score        36.211174\n",
       "F1_score              0.503719\n",
       "roc_score             0.807032"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_best_model = pd.DataFrame(model_summary, index = ['accuracy', 'jaccard score', 'F1_score', 'roc_score'],\n",
    "                          columns= [final_clf.estimators_[0]])\n",
    "summary_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Model saved in model directory\n"
     ]
    }
   ],
   "source": [
    "## Save model\n",
    "pkl_file = os.path.join(dir_path,'model', 'final_model.pkl')\n",
    "file = open(pkl_file,\"wb\")\n",
    "pickle.dump(final_clf,file)\n",
    "file.close()\n",
    "print(\"...Model saved in model directory\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Saving vectorizer in model directory\n",
      "...Saved vectorizer in model directory\n"
     ]
    }
   ],
   "source": [
    "## Save vectorizer\n",
    "print(\"...Saving vectorizer in model directory\")\n",
    "pkl_file = os.path.join(dir_path,'model', 'final_vectorizer.pkl')\n",
    "file = open(pkl_file,\"wb\")\n",
    "pickle.dump(final_vectorizer,file)\n",
    "file.close()\n",
    "print(\"...Saved vectorizer in model directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignore below part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Lets do testing on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str = [\"that is so good, i am so happy bitch\"]\n",
    "input_str = clean(input_str[0])\n",
    "input_str = process_txt(input_str, stemm= True)\n",
    "input_str = nb_vectorizer.transform([input_str])\n",
    "input_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Open the saved mode.pkl\n",
    "pkl_file = os.path.join(dir_path, 'model', 'MultinomialNB')\n",
    "open_file = open(pkl_file, \"rb\")\n",
    "model = pickle.load(open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB())"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(input_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if it needs to stay here\n",
    "**`Bag-of-Words` and `TF-IDF`**\n",
    "<br>Accuracies for `Bag-of-Words` and `TF-IDF` are not same but their difference is also not very significant for both Linear regression and Naive Bayes \n",
    "<br>Accuracy remained same - `Identity hate`, `threat`\n",
    "<br>Accuracy remained almost same - `Severe_toxic`\n",
    "<br>Accuracy improved little bit  with the use of TF-IDF but not very significant change for `Toxic`, `Obscene`, `insult`.\n",
    "One possible reason for not seeing the expected significant improvement with the use of `TF-IDF` could be - the human raters didn't care for the semantics of the sentances and rated the comment based on the presence of toxic words.\n",
    "In this case, we will choose `Bag-of-Words` because the performance is almost same as `TF-IDF` but less chance of overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc = corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf_lr_accuracy = []\n",
    "for label in labels:\n",
    "    print('\\n... PROCESSING {}'.format(label.upper()))\n",
    "    # train the model\n",
    "    clf = logreg\n",
    "\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    skf.get_n_splits(Xc,df[label])\n",
    "    \n",
    "    score_lr_acc = []\n",
    "    score_lr_jaccard = []\n",
    "    score_lr_roc = []\n",
    "    score_lr_f1 = []\n",
    "    i = 1\n",
    "    for train_index, test_index in skf.split(Xc,df[label]):\n",
    "        Y = df[label]\n",
    "        #print(\"Train:\", train_index, \"validation:\", test_index)\n",
    "        X1_train, x1_test = Xc.iloc[train_index], Xc.iloc[test_index]\n",
    "        y1_train, y1_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "        ### Convert into word embeddings\n",
    "        train_feat, test_feat, vectorizer = get_embeddings(X1_train,x1_test)\n",
    "#       bw_vectorizer = feature_extraction.text.CountVectorizer(max_features= 100)\n",
    "#       X1_train = bw_vectorizer.fit_transform(X1_train).toarray()\n",
    "#       x1_test = bw_vectorizer.fit_transform(x1_test).toarray()\n",
    "\n",
    "        clf.fit(train_feat, y1_train)\n",
    "        prediction_lr = clf.predict(test_feat)\n",
    "        \n",
    "        acc_lr_score = accuracy_score(y1_test,prediction_lr)\n",
    "        score_lr_acc.append(acc_lr_score)\n",
    "        \n",
    "        jaccard_lr = j_score(pd.DataFrame(y1_test),pd.DataFrame(prediction_lr))\n",
    "        score_lr_jaccard.append(jaccard_lr)\n",
    "        \n",
    "        roc_lr = roc_auc_score(y1_test,prediction_lr)\n",
    "        score_lr_roc.append(roc_lr)\n",
    "        \n",
    "        print(\"----- Processed {} fold\".format(i))\n",
    "        print(print_score(prediction_lr, y1_test, clf))\n",
    "        \n",
    "        i = i+1\n",
    "        \n",
    "    print(\"Model evaluation\")\n",
    "    print(\"------\")\n",
    "    print(\"ROC_AUC - {}\".format(score_lr_roc))\n",
    "    print('Average accuracy for 5 Kfolds in {} category {}'.format(label, np.array(score_lr_acc).mean()))\n",
    "    print(\"------\")\n",
    "    #print(type(score))\n",
    "    skf_lr_accuracy.append(np.array(score_lr_acc).mean())\n",
    "print(\"\\n Mean accuracies of all six labeles: {}\".format(skf_lr_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "**Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = n_bayes\n",
    "skf_nb_accuracy = []\n",
    "for label in labels:\n",
    "    print('\\n... PROCESSING {}'.format(label.upper()))\n",
    "    # train the model\n",
    "    classifier = n_bayes\n",
    "\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    skf.get_n_splits(Xc,df[label])\n",
    "    \n",
    "    score_label = []\n",
    "    score_nb_jaccard = []\n",
    "    score_nb_roc = []\n",
    "    score_nb_f1 = []\n",
    "    i = 1\n",
    "    for train_index, test_index in skf.split(Xc,df[label]):\n",
    "        Y = df[label]\n",
    "        #print(\"Train:\", train_index, \"validation:\", test_index)\n",
    "        X1_train, x1_test = Xc.iloc[train_index], Xc.iloc[test_index]\n",
    "        y1_train, y1_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "        ### Convert into word embeddings\n",
    "        train_feat, test_feat, vectorizer = get_embeddings(X1_train,x1_test)\n",
    "#       bw_vectorizer = feature_extraction.text.CountVectorizer(max_features= 100)\n",
    "#       X1_train = bw_vectorizer.fit_transform(X1_train).toarray()\n",
    "#       x1_test = bw_vectorizer.fit_transform(x1_test).toarray()\n",
    "\n",
    "        classifier.fit(train_feat, y1_train)\n",
    "        prediction = classifier.predict(test_feat)\n",
    "        \n",
    "        acc_score = accuracy_score(y1_test,prediction)\n",
    "        score_label.append(acc_score)\n",
    "        \n",
    "        jaccard_nb = j_score(pd.DataFrame(y1_test),pd.DataFrame(prediction))\n",
    "        score_nb_jaccard.append(jaccard_nb)\n",
    "        \n",
    "        roc_nb = roc_auc_score(y1_test,prediction)\n",
    "        score_nb_roc.append(roc_nb)\n",
    "        \n",
    "        print(\"----- Processed {} fold\".format(i))\n",
    "        print(print_score(prediction, y1_test, classifier))\n",
    "        \n",
    "        i = i+1\n",
    "        \n",
    "    print(\"Model evaluation\")\n",
    "    print(\"------\")\n",
    "    print(\"ROC_AUC - {}\".format(score_nb_roc))\n",
    "    print('Average accuracy for 5 Kfolds in {} category {}'.format(label, np.array(score_label).mean()))\n",
    "    print(\"------\")\n",
    "    #print(type(score))\n",
    "    skf_nb_accuracy.append(np.array(score_label).mean())\n",
    "print(\"\\n Mean accuracies of all six labeles: {}\".format(skf_nb_accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying multiple values of C in Linear regression model using simple Train-Test split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = {'toxic': 0, 'severe_toxic': 0, 'obscene': 0, 'threat': 0, 'insult': 0, 'identity_hate': 0}\n",
    "best_c_value = {}\n",
    "for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "   ### Naive bayes\n",
    "  print('\\n... Processing  C= {}'.format(c)) \n",
    "  accuracy_lr = []\n",
    "  for label in labels:\n",
    "      print('... Processing {}'.format(label))\n",
    "      # train the model \n",
    "      logreg = OneVsRestClassifier(LogisticRegression(C=c ,solver='sag'))\n",
    "      logreg.fit(Xv_train, y_train[label])\n",
    "      # compute the testing accuracy\n",
    "      prediction = logreg.predict(Xv_test)\n",
    "      score = (accuracy_score(y_test[label], prediction))\n",
    "      accuracy_lr.append(score)\n",
    "      if score > best_accuracy[label]:\n",
    "        best_accuracy[label] = score\n",
    "        best_c_value[label] = c\n",
    "      print('Validation accuracy is {}'.format(accuracy_score(y_test[label], prediction)))\n",
    "  print(\"Accuracy_lr: {}\".format(accuracy_lr))\n",
    "print(\"\\n Best accuracy : {}\".format(best_accuracy))\n",
    "print(\"Best parameter : {}\".format(best_c_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of above cell\n",
    "# Best accuracy : {'toxic': 0.9107612864412303, 'severe_toxic': 0.9900233123605645, 'obscene': 0.9515955180106785, 'threat': 0.9973679592911037, 'insult': 0.9509688416514176, 'identity_hate': 0.9910259945353821}\n",
    "# Best parameter : {'toxic': 0.1, 'severe_toxic': 0.001, 'obscene': 0.1, 'threat': 0.001, 'insult': 0.1, 'identity_hate': 0.001}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Old version to try Kfolf CV\n",
    "\n",
    "# ### OneVsRestClassifier\n",
    "# for classifier in [n_bayes,logreg]:\n",
    "    \n",
    "#     print('... Processing {}'.format(classifier))\n",
    "    \n",
    "#     #Train-test split\n",
    "#     print(\"... Performing train test split\")\n",
    "#     X_train, X_test, y_train, y_test = model_selection.train_test_split(corpus,df[labels],\n",
    "#                                                                     test_size=0.25,random_state=42)\n",
    "    \n",
    "#     ## Features extraction with word embedding\n",
    "#     print(\"... Extracting features\")\n",
    "#     Xv_train, Xv_test, vectorizer = get_embeddings(X_train, X_test,\n",
    "#                                                           max_feature = 1000 , embedding_type= 'bow')\n",
    "    \n",
    "#     # train the model \n",
    "#     print('... Training {} model'.format(classifier.__class__.__name__))\n",
    "    \n",
    "#     # train the model \n",
    "#     clf = OneVsRestClassifier(classifier)\n",
    "#     clf.fit(Xv_train, y_train)\n",
    "\n",
    "#     # compute the testing accuracy\n",
    "#     prediction = clf.predict(Xv_test)\n",
    "    \n",
    "#     score = (accuracy_score(y_test, prediction))\n",
    "#     cv_score= cross_val_score(classifier,corpus,df[labels],cv=5)\n",
    "#     roc_lr = roc_auc_score(y1_test,prediction_lr)\n",
    "    \n",
    "#     ## Save model\n",
    "#     pkl_file = os.path.join(dir_path,'model', classifier.__class__.__name__)\n",
    "#     file = open(pkl_file,\"wb\")\n",
    "#     pickle.dump(clf,file)\n",
    "#     file.close()\n",
    "    \n",
    "#     #### Prediction on comment \n",
    "        \n",
    "#     input_str = [\"i'm going to kill you nigga, you are you sick or mad, i don't like you at all\"]\n",
    "#     input_str = clean(input_str[0])\n",
    "#     input_str = process_txt(input_str, stemm= True)\n",
    "#     input_str = vectorizer.transform([input_str])\n",
    "    \n",
    "#     print(\"KFold score {}\".format(cv_score))\n",
    "#     print(print_score(prediction, y_test, classifier))\n",
    "#     print(print(\"check model accuracy on input_string {}\".format(clf.predict(input_str))))\n",
    "#     print('Validation accuracy is {}'.format(score))\n",
    "#     print(\"------\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Linear regression for kfold CV\n",
    "# cv_accuracy_lr = []\n",
    "# accuracy_lr = []\n",
    "# for label in labels:\n",
    "#     print('... Processing {}'.format(label))\n",
    "#     # train the model \n",
    "#     clf = OneVsRestClassifier(logreg)\n",
    "#     clf.fit(Xv_train, y_train[label])\n",
    "#     # compute the testing accuracy\n",
    "#     prediction = logreg.predict(Xv_test)\n",
    "#     score = (accuracy_score(y_test[label], prediction))\n",
    "#     cv_score= cross_val_score(logreg,X,df[labels],cv=10)\n",
    "#     accuracy_lr.append(score)\n",
    "    \n",
    "#     print('Validation accuracy is {}'.format(accuracy_score(y_test[label], prediction)))\n",
    "#     print('\\n cv_score = {}'.format(cv_score))\n",
    "# print(\"\\n Accuracy_lr: {}\".format(accuracy_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Naive bayes\n",
    "# accuracy_nb = []\n",
    "# for label in labels:\n",
    "#     print('\\n... Processing {}'.format(label))\n",
    "#     # train the model \n",
    "#     nbayes = OneVsRestClassifier(naive_bayes.MultinomialNB())\n",
    "#     nbayes.fit(Xv_train, y_train[label])\n",
    "#     # compute the testing accuracy\n",
    "#     prediction = nbayes.predict(Xv_test)\n",
    "#     score = (accuracy_score(y_test[label], prediction))\n",
    "#     cv_score= cross_val_score(nbayes,X,df[labels],cv=10)\n",
    "#     accuracy_nb.append(score)\n",
    "#     print('Validation accuracy is {}'.format(score))\n",
    "#     print('cv_score = {}'.format(cv_score))\n",
    "# print(\"\\n Accuracy_nb: {}\".format(accuracy_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Performing train test split\n"
     ]
    }
   ],
   "source": [
    "#Train-test split\n",
    "print(\"... Performing train test split\")\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(corpus,df[labels],\n",
    "                                                                    test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Extracting features\n"
     ]
    }
   ],
   "source": [
    "## Features extraction with word embedding\n",
    "print(\"... Extracting features\")\n",
    "Xv_train, Xv_test, vectorizer = get_embeddings(X_train, X_test,\n",
    "                                                          max_feature = 1000 , embedding_type= 'bow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
